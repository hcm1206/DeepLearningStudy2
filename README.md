# DeepLearningStudy2

딥러닝 공부하면서 실습한 파일 정리하는 곳

Deep Learning from Scratch 밑바닥부터 시작하는 딥러닝 2(사이토 고키, 한빛 미디어) 책 기반

<a href="https://github.com/hcm1206/DeepLearningStudy">DeepLearningStudy</a> 후속 공부

******
  
2022-12-26 딥러닝 공부 시즌 2 개시  
   
******
  
## 최근 진행 내용
  

### 2023-01-15
#### Chapter1  
1.3 ~ 1.3.6(p.39~p.62)
- 신경망에서 학습을 진행할 때 어느 시점의 신경망 성능을 나타내는 척도로 손실(loss) 값을 사용
- 손실은 손실 함수(loss function)을 통해 구하며 다중 클래스 분류 신경망에서는 대표적으로 교차 엔트로피 오차를 손실 함수로 이용
- 교차 엔트로피 오차 계층에서 입력 데이터를 x, 정답 레이블을 t, 손실을 L로 표현
- 먼저 소프트맥스 함수를 이용하여 계산 결과를 정규화하고, 정규화된 값을 교차 엔트로피 오차를 이용하여 손실 값을 구하는 순서로 적용
- 손실을 최소화하는 값을 찾기 위하여 오차역전파법을 이용해서 미분과 기울기를 구하는 과정 필요
- 계산 그래프를 통해 각 계산 노드 구현 : 덧셈 노드, 곱셈 노드, 분기 노드, Repeat 노드, Sum 노드, Matmul 노드
- 오차역전파법이 적용된 Sigmoid 계층, Affine 계층, Softmax with Lostt 계층을 클래스로 구현
- 오차역전파법으로 구한 기울기를 이용하여 매개변수를 갱신하는 과정을 반복함으로써 신경망 학습이 이루어짐
- 가중치 갱신 기법에는 여러 종류가 있으며 그 중 가장 간단한 SGD 기법은 무작위로 선택된 데이터에 대한 기울기를 일정한 학습률과 곱하여 매개변수를 갱신하는 방법
  
******
  





