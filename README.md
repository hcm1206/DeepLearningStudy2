# DeepLearningStudy2

딥러닝 공부하면서 실습한 파일 정리하는 곳

Deep Learning from Scratch 밑바닥부터 시작하는 딥러닝 2(사이토 고키, 한빛 미디어) 책 기반

<a href="https://github.com/hcm1206/DeepLearningStudy">DeepLearningStudy</a> 후속 공부

******
  
> 2022-12-26 딥러닝 공부 시즌 2 개시  
  
  
> 책에서 제공하는 코드들 중 조건에 따라 아래와 같이 저장  
> - 클래스 및 기능 부분 : common 폴더  
> - 학습용 데이터셋 : dataset 폴더  
> - 실습 코드 중 다른 코드에서 추가적으로 불러서 사용하는 코드 : files 폴더  
  
  
> 책에서는 상위 디렉토리 접근을 위하여 ```sys.path.append('..')``` 코드를 사용하였으나 작동하지 않는 관계로(아나콘다 실행 환경과 충돌하는 것으로 추정)  
> 해당 코드를 ```sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(__file__))))```로 변경  
   
******
  
## 최근 진행 내용

### 2023-05-02
#### Chapter5
5 ~ 5.3.2(p.191~p.220)
- 피드포워드 신경망 : 데이터 흐름이 단방향으로만 전달되는 신경망  
- 순환 신경망(RNN) : 순환하는 닫힌 경로가 있어 데이터 흐름이 순환할 수 있는 신경망  
- 인접한 긴 길이의 맥락 데이터를 다루는 언어모델 같은 경우 피드포워드 신경망보다 순환 신경망을 사용하는 것이 유리  
- RNN 신경망은 같은 동작을 수행하는 RNN 계층을 이어붙여 구현 가능  
- RNN 신경망에서는 이전 RNN 계층에서의 출력값이 현재 RNN 계층에 영향을 주고, 현재 RNN 계층의 출력값이 미래 RNN 계층에 영향을 주는 관계를 가짐  
- RNN에서의 은닉 상태 h는 RNN 신경망에서 '상태'역할을 하며 출력되기도 하고 다음 RNN 계층으로 입력되기도 함  
- BPTT : RNN 신경망의 역전파 계산을 하기 위해 시간 방향으로 펼친 신경망의 오차역전파법 기법  
- 일반적인 BPTT는 높은 컴퓨팅 자원을 소비하고 시간 크기가 커지면 역전파 시의 기울기가 불안정해지는 문제 발생  
- Truncated BPTT : 역전파 계산 시 일정한 길이로 끊어서 잘라낸 신경망 단위로 역전파 계산을 진행하고 학습을 수행하는 기법   
- Truncated BPTT에서 미니배치 학습 시 미니배치 시작 지점의 데이터부터 순서대로 묶어서 학습해야 함  
- 한 번의 순환을 담당하는 단일 RNN 계층 클래스 구현  
- 단일 RNN 계층을 T개로 묶어 RNN 신경망을 구성하는 Time RNN 계층 클래스 구현  

### 2023-04-28
#### Chapter4
4.3 ~ 4.5(p.176~p.190)
- Embedding 계층과 Nagative Sampling Loss 계층을 추가학 맥락 윈도우 크기를 설정 가능한 개선된 CBOW 모델 구현  
- PTB 데이터셋을 이용하여 개선된 CBOW 모델 학습  
- 학습된 CBOW 모델의 매개변수를 피클 파일로 저장하여 사용 가능  
- 학습된 CBOW 모델을 통해 몇 가지 단어의 유사 단어 목록 추출  
- word2vec의 단어 분산 표현은 단어의 복잡한 패턴을 파악하는 유추 문제에도 적용 가능  
- 전이 학습 : 한 분야에서 배운 지식을 다른 분야에도 적용하는 기법  
- 자연어 처리를 통해 얻은 단어 분산 표현은 전이 학습을 통해 다른 다양한 분야에 응용 가능  
- 단어 분산 표현은 문자열인 단어를 고정 길이 숫자 벡터로 변환하여 일반적인 머신러닝 기법을 적용할 수 있게끔 해주는 역할도 수행  
- 단어 분산 표현 시스템과 이 단어 분산 표현을 사용하는 응용 어플리케이션의 성능은 서로 분리하여 측정하는 것이 일반적  
- 자주 사용하는 단어 분산 표현 평가 척도는 '단어의 유사성'과 '유추 문제'를 이용한 평가로, 보통 사람이 직접 평가  
- 단어 분산 표현 시스템의 성능은 모델에 따라 정확도가 다르고, 말뭉치가 클수록 결과가 좋으며, 단어 벡터 차원 수는 작지도 크기도 않은 적당한 크기가 좋음  
- 단어 분산 표현 시스템 성능과 사용하는 애플리케이션의 성능은 비례하지 않고 여러가지 요소에 의해 다를 수 있음  