# DeepLearningStudy2

딥러닝 공부하면서 실습한 파일 정리하는 곳

Deep Learning from Scratch 밑바닥부터 시작하는 딥러닝 2(사이토 고키, 한빛 미디어) 책 기반

<a href="https://github.com/hcm1206/DeepLearningStudy">DeepLearningStudy</a> 후속 공부

******
  
>> 2022-12-26 딥러닝 공부 시즌 2 개시  
  
  
>> 책에서 제공하는 코드들 중 조건에 따라 아래와 같이 저장  
>> 클래스 및 기능 부분 : common 폴더  
>> 학습용 데이터셋 : dataset 폴더  
>> 실습 코드 중 다른 코드에서 추가적으로 불러서 사용하는 코드 : files 폴더  
  
  
>> 책에서는 상위 디렉토리 접근을 위하여 sys.path.append('..') 코드를 사용하였으나 작동하지 않는 관계로(아나콘다 실행 환경과 충돌하는 것으로 추정)  
>> 해당 코드를 sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(__file__))))로 변경  
   
******
  
## 최근 진행 내용

### 2023-01-18
#### Chapter1  
1.4 ~ 1.4.4(p.62~p.71)
- 신경망 테스트를 위해 3개의 클래스로 구분되어 있으며 각 레이블 데이터가 나선형 모습으로 분포되어있는 spiral 데이터 이용 
- 가중치와 편향 매개변수, 그리고 각 계층(Affine, Sigmoid, SoftmaxWithLoss)이 저장되어 있고 순전파 및 역전파 계산이 가능한 2층 신경망 TwoLayerNet 클래스 구현
- TwoLayerNet 클래스에 저장된 신경망에서 학습이 이루어지도록 하이퍼파라미터와 옵티마이저를 설정하여 신경망 학습 구현
- 책에서 제공하는 Trainer 클래스 사용법 확인 : 신경망 학습 시 일정 간격 별 손실 값 출력 기능 및 학습 후 손실값 그래프 출력 기능 포함
  

### 2023-01-15
#### Chapter1  
1.3 ~ 1.3.6(p.39~p.62)
- 신경망에서 학습을 진행할 때 어느 시점의 신경망 성능을 나타내는 척도로 손실(loss) 값을 사용
- 손실은 손실 함수(loss function)을 통해 구하며 다중 클래스 분류 신경망에서는 대표적으로 교차 엔트로피 오차를 손실 함수로 이용
- 교차 엔트로피 오차 계층에서 입력 데이터를 x, 정답 레이블을 t, 손실을 L로 표현
- 먼저 소프트맥스 함수를 이용하여 계산 결과를 정규화하고, 정규화된 값을 교차 엔트로피 오차를 이용하여 손실 값을 구하는 순서로 적용
- 손실을 최소화하는 값을 찾기 위하여 오차역전파법을 이용해서 미분과 기울기를 구하는 과정 필요
- 계산 그래프를 통해 각 계산 노드 구현 : 덧셈 노드, 곱셈 노드, 분기 노드, Repeat 노드, Sum 노드, Matmul 노드
- 오차역전파법이 적용된 Sigmoid 계층, Affine 계층, Softmax with Lostt 계층을 클래스로 구현
- 오차역전파법으로 구한 기울기를 이용하여 매개변수를 갱신하는 과정을 반복함으로써 신경망 학습이 이루어짐
- 가중치 갱신 기법에는 여러 종류가 있으며 그 중 가장 간단한 SGD 기법은 무작위로 선택된 데이터에 대한 기울기를 일정한 학습률과 곱하여 매개변수를 갱신하는 방법
  
******
  





