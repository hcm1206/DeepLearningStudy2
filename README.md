# DeepLearningStudy2

딥러닝 공부하면서 실습한 파일 정리하는 곳

Deep Learning from Scratch 밑바닥부터 시작하는 딥러닝 2(사이토 고키, 한빛 미디어) 책 기반

<a href="https://github.com/hcm1206/DeepLearningStudy">DeepLearningStudy</a> 후속 공부

******
  
2022-12-26 딥러닝 공부 시즌 2 개시  
   
******
  
## 최근 진행 내용
  

### 2022-12-28
#### Chapter1  
1.2 ~ 1.2.2(p.30~p.39)
- 신경망에서 수행하는 작업은 '추론(순전파)'과 '학습(역전파)'
- 2차원 데이터를 입력하여 3차원 데이터로 변환하는 간단한 신경망 구성
- 신경망은 입력층, 은닉층, 출력층으로 구분
- 은닉층의 뉴련은 가중치의 합으로 계산되며, 입력값과의 행렬 곱에 편향을 더하여 모든 은닉층의 값 계산 가능
- 가중치와 편향을 이용한 은닉층 계산은 선형 변환인 '완전연결계층'이며, 이를 비선형 변환으로 전환하기 위하여 활성화 함수 사용
- 활성화 함수로 시그모이드(Sigmoid) 함수 사용
- 신경망의 각 계층을 클래스를 통해 모듈화하여 구현 가능
- 입력값 크기 2, 은닉층 크기 4, 출력층 크기 3의 신경망 모델을 구현하여 순전파 계산 실습
  
  
### 2022-12-26
#### Chapter1  
1 ~ 1.1.5(p.23~p.29)
- 밑바닥부터 시작하는 딥러닝 속편으로 시작
- 수학 개념과 파이썬 코드 복습
- 벡터 : 크기와 방향을 가진 양으로, 숫자가 일렬로 늘어선 집합으로 표현, 1차원 행렬로 취급 가능
- 행렬 : 숫자가 2차원 형태로 늘어선 것, m행 n열의 행렬을 m×n 행렬이라고 표현
- 행렬의 원소별 연산 : 연산할 행렬들에서 서로 대응하는 원소를 독립적으로 연산
- 브로드캐스트 : numpy의 다차원 배열 연산에서 형상이 다른 배열끼리 연산할 수 있는 기능
- 벡터의 내적 : 두 벡터에서 대응하는 원소들의 곱을 모두 더한 값
- 행렬의 곱 : 왼쪽 행렬의 행(가로) 벡터와 오른쪽 행렬의 열(세로) 벡터의 내적을 대응하는 원소에 저장한 행렬
- 행렬 곱의 결과는 (왼쪽 행렬의 행 크기) × (오른쪽 행렬의 열 크기) 형상의 행렬
- 행렬 연산 시 연산할 두 행렬의 형상에 주의
  
******
  
## 오늘의 한줄평
  
### 2022-12-28
  
엘렐레 에베베베베베벱베ㅔㅂ베ㅔㅂ  
  





